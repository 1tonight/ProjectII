{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dbb328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterio.enums import Resampling as RasterioResampling\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys \n",
    "import random\n",
    "\n",
    "\n",
    "MODEL_FILENAME_TO_TEST = \"20250705-060518_UnetPlusPlus_efficientnet-b7_best.pth\"\n",
    "\n",
    "BASE_DATA_PATH = \"Project II\"   #phải sửa lại path này cho phù hợp với hệ thống \n",
    "OUTPUT_DIR = \"Project II/outputs\"   #phải sửa lại path này cho phù hợp với hệ thống \n",
    "\n",
    "\n",
    "# Cấu hình model \n",
    "\n",
    "BATCH_SIZE = 4\n",
    "PATCH_SIZE = 256\n",
    "TERRAIN_THRESHOLD = 0.2\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Hàm tải và tiền xử lý dữ liệu\n",
    "def load_and_preprocess_pair(dsm_path, dem_path, terrain_threshold):\n",
    "    try:\n",
    "        with rasterio.open(dsm_path) as dsm_src, rasterio.open(dem_path) as dem_src:\n",
    "            if dsm_src.crs != dem_src.crs:\n",
    "                return None, None\n",
    "            \n",
    "            left = max(dsm_src.bounds.left, dem_src.bounds.left)\n",
    "            bottom = max(dsm_src.bounds.bottom, dem_src.bounds.bottom)\n",
    "            right = min(dsm_src.bounds.right, dem_src.bounds.right)\n",
    "            top = min(dsm_src.bounds.top, dem_src.bounds.top)\n",
    "\n",
    "            if left >= right or bottom >= top:\n",
    "                return None, None\n",
    "                \n",
    "            window = from_bounds(left, bottom, right, top, dem_src.transform)\n",
    "            dem_nodata = dem_src.nodata if dem_src.nodata is not None else -9999\n",
    "            dsm_nodata = dsm_src.nodata if dsm_src.nodata is not None else -9999\n",
    "            dem_data = dem_src.read(1, window=window, boundless=True, fill_value=dem_nodata).astype(np.float32)\n",
    "            dsm_data = dsm_src.read(1, window=window, out_shape=dem_data.shape, boundless=True, fill_value=dsm_nodata, resampling=RasterioResampling.nearest).astype(np.float32)\n",
    "            \n",
    "            valid_mask = (dsm_data != dsm_nodata) & (dem_data != dem_nodata)\n",
    "            label_mask = np.zeros_like(dem_data, dtype=np.float32)\n",
    "            is_terrain = np.abs(dsm_data - dem_data) <= terrain_threshold\n",
    "            label_mask[valid_mask & is_terrain] = 1.0\n",
    "            \n",
    "            if np.any(valid_mask):\n",
    "                mean_val = np.mean(dsm_data[valid_mask])\n",
    "                std_val = np.std(dsm_data[valid_mask])\n",
    "                if std_val > 1e-6:\n",
    "                    dsm_normalized = (dsm_data - mean_val) / std_val\n",
    "                    dsm_normalized[~valid_mask] = 0\n",
    "                else:\n",
    "                    dsm_normalized = np.zeros_like(dsm_data)\n",
    "            else:\n",
    "                dsm_normalized = np.zeros_like(dsm_data)\n",
    "                \n",
    "            return dsm_normalized, label_mask\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi xử lý cặp file {os.path.basename(dsm_path)}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Lớp Dataset\n",
    "class GeoTiffPatchDataset(Dataset):\n",
    "    def __init__(self, file_pairs, patch_size, terrain_threshold):\n",
    "        self.file_pairs = file_pairs\n",
    "        self.patch_size = patch_size\n",
    "        self.terrain_threshold = terrain_threshold\n",
    "        self.patches = self._create_patches()\n",
    "\n",
    "    def _create_patches(self):\n",
    "        patches = []\n",
    "        print(\"Đang tạo các patch từ file ảnh lớn...\")\n",
    "        for dsm_path, dem_path in tqdm(self.file_pairs):\n",
    "            dsm_full, mask_full = load_and_preprocess_pair(dsm_path, dem_path, self.terrain_threshold)\n",
    "            if dsm_full is not None:\n",
    "                img_height, img_width = dsm_full.shape\n",
    "                for y in range(0, img_height, self.patch_size):\n",
    "                    for x in range(0, img_width, self.patch_size):\n",
    "                        dsm_patch = dsm_full[y:y+self.patch_size, x:x+self.patch_size]\n",
    "                        mask_patch = mask_full[y:y+self.patch_size, x:x+self.patch_size]\n",
    "                        pad_h = self.patch_size - dsm_patch.shape[0]\n",
    "                        pad_w = self.patch_size - dsm_patch.shape[1]\n",
    "                        if pad_h > 0 or pad_w > 0:\n",
    "                            dsm_patch = np.pad(dsm_patch, ((0, pad_h), (0, pad_w)), mode='constant', constant_values=0)\n",
    "                            mask_patch = np.pad(mask_patch, ((0, pad_h), (0, pad_w)), mode='constant', constant_values=0)\n",
    "                        if np.any(mask_patch):\n",
    "                            patches.append((dsm_patch, mask_patch))\n",
    "        return patches\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dsm_patch, mask_patch = self.patches[idx]\n",
    "        dsm_tensor = torch.from_numpy(dsm_patch).float().unsqueeze(0)\n",
    "        mask_tensor = torch.from_numpy(mask_patch).float().unsqueeze(0)\n",
    "        return dsm_tensor, mask_tensor\n",
    "\n",
    "# CÁC HÀM ĐÁNH GIÁ MÔ HÌNH\n",
    "# Hàm validate_one_epoch\n",
    "def validate_one_epoch(model, dataloader, loss_fn_1, loss_fn_2, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    epoch_tp, epoch_fp, epoch_fn, epoch_tn = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(dataloader, desc=\"Calculating Metrics\")\n",
    "        for inputs, labels in progress_bar:\n",
    "            # ... (phần code bên trong vòng lặp giữ nguyên)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn_1(outputs, labels) + loss_fn_2(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).long()\n",
    "            labels_long = labels.long()\n",
    "            tp, fp, fn, tn = smp.metrics.get_stats(preds, labels_long, mode='binary')\n",
    "            epoch_tp += tp.sum(); epoch_fp += fp.sum(); epoch_fn += fn.sum(); epoch_tn += tn.sum()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    \n",
    "    # Trả về một dictionary chứa tất cả các chỉ số\n",
    "    metrics = {\n",
    "        \"loss\": avg_loss,\n",
    "        \"iou\": smp.metrics.iou_score(epoch_tp, epoch_fp, epoch_fn, epoch_tn, reduction='micro').item(),\n",
    "        \"f1_score\": smp.metrics.f1_score(epoch_tp, epoch_fp, epoch_fn, epoch_tn, reduction='micro').item(),\n",
    "        \"precision\": smp.metrics.precision(epoch_tp, epoch_fp, epoch_fn, epoch_tn, reduction='micro').item(),\n",
    "        \"recall\": smp.metrics.recall(epoch_tp, epoch_fp, epoch_fn, epoch_tn, reduction='micro').item()\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Hàm Hiển thị Kết quả\n",
    "def visualize_predictions(model, dataloader, device, save_path, num_examples=5):\n",
    "    model.eval()\n",
    "    plt.figure(figsize=(15, num_examples * 5))\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    if num_batches == 0:\n",
    "        print(\"Lỗi: Test Dataloader rỗng, không có dữ liệu để hiển thị.\")\n",
    "        return\n",
    "\n",
    "    \n",
    "    # Lấy số lượng batch random, nếu muốn chỉ định có thể để i == \"số thứ tự file chỉ định\" trong vòng lặp for\n",
    "    random_batch_idx = random.randint(0, num_batches - 1)\n",
    "    print(f\"Hiển thị các ảnh từ batch ngẫu nhiên số {random_batch_idx + 1}/{num_batches}...\")\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        if i == random_batch_idx:\n",
    "            inputs, labels = batch\n",
    "            break\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        \n",
    "    inputs_np = inputs.cpu().numpy()\n",
    "    labels_np = labels.cpu().numpy()\n",
    "    preds_np = preds.cpu().numpy()\n",
    "    \n",
    "    for i in range(min(num_examples, len(inputs_np))):\n",
    "        plt.subplot(num_examples, 3, i * 3 + 1)\n",
    "        plt.imshow(inputs_np[i, 0, :, :], cmap='viridis')\n",
    "        plt.title(f\"Input DSM Patch {i + 1}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(num_examples, 3, i * 3 + 2)\n",
    "        plt.imshow(labels_np[i, 0, :, :], cmap='gray')\n",
    "        plt.title(f\"Ground Truth Mask {i + 1}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(num_examples, 3, i * 3 + 3)\n",
    "        plt.imshow(preds_np[i, 0, :, :], cmap='gray')\n",
    "        plt.title(f\"Predicted Mask {i + 1}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"Ảnh ví dụ dự đoán đã được lưu tại: {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "#-TẢI DỮ LIỆU, CHẠY ĐÁNH GIÁ VÀ HIỂN THỊ\n",
    "\n",
    "print(\"Script Test Model Bắt đầu\")\n",
    "print(f\"Sử dụng thiết bị: {DEVICE.upper()}\")\n",
    "\n",
    "# Tự động trích xuất kiến trúc và backbone từ tên file\n",
    "try:\n",
    "    # Bỏ đi phần timestamp \n",
    "    name_without_timestamp = MODEL_FILENAME_TO_TEST.split('_', 1)[1]\n",
    "    \n",
    "    # Bỏ đi phần đuôi '_best.pth'\n",
    "    clean_name = name_without_timestamp.replace('_best.pth', '')\n",
    "    \n",
    "    # Tách kiến trúc và backbone \n",
    "    parts = clean_name.split('_', 1)\n",
    "    MODEL_ARCHITECTURE = parts[0]\n",
    "    MODEL_BACKBONE = parts[1] \n",
    "    \n",
    "    print(f\"Đã nhận diện model: Kiến trúc={MODEL_ARCHITECTURE}, Backbone={MODEL_BACKBONE}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"LỖI: Tên file '{MODEL_FILENAME_TO_TEST}' không đúng định dạng hoặc có lỗi khi xử lý. Lỗi: {e}\")\n",
    "    sys.exit() # Thoát chương trình nếu tên file sai\n",
    "\n",
    "# Tải và chuẩn bị đường dẫn file test ---\n",
    "DSM_DIR = os.path.join(BASE_DATA_PATH, 'DSM')\n",
    "DEM_DIR = os.path.join(BASE_DATA_PATH, 'DEM')\n",
    "dsm_pattern = os.path.join(DSM_DIR, '**', '*.TIF')\n",
    "dem_pattern = os.path.join(DEM_DIR, '**', '*.TIF')\n",
    "dsm_files = sorted(glob.glob(dsm_pattern, recursive=True))\n",
    "dem_files = sorted(glob.glob(dem_pattern, recursive=True))\n",
    "dem_dict = {os.path.basename(f).replace('dem', 'dsm'): f for f in dem_files}\n",
    "file_pairs = [];\n",
    "for dsm_file in dsm_files:\n",
    "    base_name = os.path.basename(dsm_file)\n",
    "    if base_name in dem_dict: file_pairs.append((dsm_file, dem_dict[base_name]))\n",
    "train_val_pairs, test_pairs = train_test_split(file_pairs, test_size=0.15, random_state=42)\n",
    "print(f\"Đã tìm thấy {len(test_pairs)} cặp file trong tập test.\")\n",
    "\n",
    "# Tải model\n",
    "model_class = getattr(smp, MODEL_ARCHITECTURE)\n",
    "best_model = model_class(encoder_name=MODEL_BACKBONE, encoder_weights=\"imagenet\", in_channels=1, classes=1).to(DEVICE)  \n",
    "# Phải sửa imagenet thành advprop nếu khác weight\n",
    "best_model_path = os.path.join(OUTPUT_DIR, MODEL_FILENAME_TO_TEST)\n",
    "best_model.load_state_dict(torch.load(best_model_path))\n",
    "print(f\"Đã tải model tốt nhất từ: {best_model_path}\")\n",
    "\n",
    "# Định nghĩa các hàm loss\n",
    "loss_fn_1 = smp.losses.DiceLoss(mode='binary')\n",
    "loss_fn_2 = smp.losses.SoftBCEWithLogitsLoss()\n",
    "\n",
    "# Tạo test_dataset và test_loader ---\n",
    "test_dataset = GeoTiffPatchDataset(test_pairs, PATCH_SIZE, TERRAIN_THRESHOLD)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "# --- BƯỚC 1: Chạy đánh giá định lượng (TÍNH TOÁN CHỈ SỐ) ---\n",
    "print(\"\\n--- Đang tính toán các chỉ số trên tập test... ---\")\n",
    "test_metrics = validate_one_epoch(best_model, test_loader, loss_fn_1, loss_fn_2, DEVICE)\n",
    "\n",
    "print(\"\\n--- KẾT QUẢ ĐỊNH LƯỢNG ---\")\n",
    "print(f\"  Test Loss:    {test_metrics['loss']:.4f}\")\n",
    "print(f\"  Test IoU:     {test_metrics['iou']:.4f}\")\n",
    "print(f\"  Test F1-Score:  {test_metrics['f1_score']:.4f}\")\n",
    "print(f\"  Test Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"  Test Recall:    {test_metrics['recall']:.4f}\")\n",
    "\n",
    "# --- BƯỚC 2: Chạy hiển thị định tính (HIỂN THỊ HÌNH ẢNH) ---\n",
    "print(\"\\n--- KẾT QUẢ ĐỊNH TÍNH (VÍ DỤ DỰ ĐOÁN) ---\")\n",
    "prediction_save_path = os.path.join(OUTPUT_DIR, f\"{MODEL_FILENAME_TO_TEST.replace('_best.pth', '')}_predictions.png\")\n",
    "visualize_predictions(best_model, test_loader, DEVICE, prediction_save_path)\n",
    "\n",
    "print(\"\\n--- QUÁ TRÌNH ĐÁNH GIÁ HOÀN TẤT ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
